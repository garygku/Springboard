{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>90258</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>73704</td>\n",
       "      <td>81542.6</td>\n",
       "      <td>119929</td>\n",
       "      <td>68844.9</td>\n",
       "      <td>82077.1</td>\n",
       "      <td>...</td>\n",
       "      <td>44223.6</td>\n",
       "      <td>44831</td>\n",
       "      <td>45878</td>\n",
       "      <td>50369.7</td>\n",
       "      <td>56479.8</td>\n",
       "      <td>75432</td>\n",
       "      <td>64530.4</td>\n",
       "      <td>54698.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53678.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1995-06-01</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>82382.8</td>\n",
       "      <td>121887</td>\n",
       "      <td>69052.5</td>\n",
       "      <td>81630.7</td>\n",
       "      <td>...</td>\n",
       "      <td>44113</td>\n",
       "      <td>45392.6</td>\n",
       "      <td>45680</td>\n",
       "      <td>50100.4</td>\n",
       "      <td>56288.9</td>\n",
       "      <td>75606.2</td>\n",
       "      <td>65511</td>\n",
       "      <td>54420.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53735.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1995-07-01</td>\n",
       "      <td>110128</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>74127</td>\n",
       "      <td>82898.5</td>\n",
       "      <td>124028</td>\n",
       "      <td>69142.5</td>\n",
       "      <td>82352.2</td>\n",
       "      <td>...</td>\n",
       "      <td>44109.6</td>\n",
       "      <td>45535</td>\n",
       "      <td>46037.7</td>\n",
       "      <td>49860</td>\n",
       "      <td>57242.3</td>\n",
       "      <td>75984.2</td>\n",
       "      <td>65224.9</td>\n",
       "      <td>54265.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53900.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1995-08-01</td>\n",
       "      <td>112329</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>73547</td>\n",
       "      <td>82054.4</td>\n",
       "      <td>125530</td>\n",
       "      <td>68993.4</td>\n",
       "      <td>82706.7</td>\n",
       "      <td>...</td>\n",
       "      <td>44193.7</td>\n",
       "      <td>45111.5</td>\n",
       "      <td>45922.5</td>\n",
       "      <td>49598.5</td>\n",
       "      <td>56732.4</td>\n",
       "      <td>75529.3</td>\n",
       "      <td>64851.6</td>\n",
       "      <td>54365.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53600.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>104473</td>\n",
       "      <td>51471.6</td>\n",
       "      <td>93273.1</td>\n",
       "      <td>64509.5</td>\n",
       "      <td>73789.5</td>\n",
       "      <td>81440.4</td>\n",
       "      <td>120597</td>\n",
       "      <td>69393.5</td>\n",
       "      <td>82011.1</td>\n",
       "      <td>...</td>\n",
       "      <td>44088.1</td>\n",
       "      <td>44837.9</td>\n",
       "      <td>45771.7</td>\n",
       "      <td>49319.7</td>\n",
       "      <td>56259.3</td>\n",
       "      <td>74940.8</td>\n",
       "      <td>64352.5</td>\n",
       "      <td>54244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53309.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley  \\\n",
       "0        NaT      E09000001          E09000002  E09000003  E09000004   \n",
       "1 1995-01-01          91449            50460.2    93284.5    64958.1   \n",
       "2 1995-02-01        82202.8            51085.8    93190.2    64787.9   \n",
       "3 1995-03-01        79120.7              51269    92247.5    64367.5   \n",
       "4 1995-04-01        77101.2            53133.5    90762.9    64277.7   \n",
       "5 1995-05-01        84409.1            53042.2      90258    63997.1   \n",
       "6 1995-06-01        94900.5            53700.3    90107.2    64252.3   \n",
       "7 1995-07-01         110128            52113.1    91441.2    63722.7   \n",
       "8 1995-08-01         112329            52232.2    92361.3    64432.6   \n",
       "9 1995-09-01         104473            51471.6    93273.1    64509.5   \n",
       "\n",
       "       Brent    Bromley     Camden    Croydon     Ealing  ... NORTH WEST  \\\n",
       "0  E09000005  E09000006  E09000007  E09000008  E09000009  ...  E12000002   \n",
       "1    71306.6    81671.5     120933    69158.2    79885.9  ...    43958.5   \n",
       "2    72022.3    81657.6     119509    68951.1    80897.1  ...    43925.4   \n",
       "3    72015.8    81449.3     120282    68712.4    81379.9  ...    44434.9   \n",
       "4    72965.6    81124.4     120098      68610    82188.9  ...    44267.8   \n",
       "5      73704    81542.6     119929    68844.9    82077.1  ...    44223.6   \n",
       "6    74310.5    82382.8     121887    69052.5    81630.7  ...      44113   \n",
       "7      74127    82898.5     124028    69142.5    82352.2  ...    44109.6   \n",
       "8      73547    82054.4     125530    68993.4    82706.7  ...    44193.7   \n",
       "9    73789.5    81440.4     120597    69393.5    82011.1  ...    44088.1   \n",
       "\n",
       "  YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON  \\\n",
       "0          E12000003     E12000004     E12000005       E12000006  E12000007   \n",
       "1            44803.4       45544.5       48527.5         56701.6    74435.8   \n",
       "2            44528.8       46051.6       49341.3         56593.6    72777.9   \n",
       "3            45200.5       45383.8       49442.2         56171.2    73896.8   \n",
       "4            45614.3       46124.2       49455.9         56567.9    74455.3   \n",
       "5              44831         45878       50369.7         56479.8      75432   \n",
       "6            45392.6         45680       50100.4         56288.9    75606.2   \n",
       "7              45535       46037.7         49860         57242.3    75984.2   \n",
       "8            45111.5       45922.5       49598.5         56732.4    75529.3   \n",
       "9            44837.9       45771.7       49319.7         56259.3    74940.8   \n",
       "\n",
       "  SOUTH EAST SOUTH WEST Unnamed: 47    England  \n",
       "0  E12000008  E12000009         NaN  E92000001  \n",
       "1    64018.9    54705.2         NaN    53202.8  \n",
       "2      63715    54356.1         NaN    53096.2  \n",
       "3    64113.6    53583.1         NaN    53201.3  \n",
       "4    64623.2      54786         NaN    53590.9  \n",
       "5    64530.4    54698.8         NaN    53678.2  \n",
       "6      65511    54420.2         NaN    53735.2  \n",
       "7    65224.9    54265.9         NaN    53900.6  \n",
       "8    64851.6    54365.7         NaN    53600.3  \n",
       "9    64352.5      54244         NaN    53309.2  \n",
       "\n",
       "[10 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.describe()\n",
    "properties.shape\n",
    "properties.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>NaN</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>81542.6</td>\n",
       "      <td>82382.8</td>\n",
       "      <td>82898.5</td>\n",
       "      <td>82054.4</td>\n",
       "      <td>...</td>\n",
       "      <td>430002</td>\n",
       "      <td>434257</td>\n",
       "      <td>442189</td>\n",
       "      <td>441058</td>\n",
       "      <td>439178</td>\n",
       "      <td>436080</td>\n",
       "      <td>438682</td>\n",
       "      <td>435337</td>\n",
       "      <td>436544</td>\n",
       "      <td>430033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>120933</td>\n",
       "      <td>119509</td>\n",
       "      <td>120282</td>\n",
       "      <td>120098</td>\n",
       "      <td>119929</td>\n",
       "      <td>121887</td>\n",
       "      <td>124028</td>\n",
       "      <td>125530</td>\n",
       "      <td>...</td>\n",
       "      <td>871957</td>\n",
       "      <td>890288</td>\n",
       "      <td>863171</td>\n",
       "      <td>838170</td>\n",
       "      <td>804713</td>\n",
       "      <td>825336</td>\n",
       "      <td>807124</td>\n",
       "      <td>816906</td>\n",
       "      <td>818558</td>\n",
       "      <td>881096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>68610</td>\n",
       "      <td>68844.9</td>\n",
       "      <td>69052.5</td>\n",
       "      <td>69142.5</td>\n",
       "      <td>68993.4</td>\n",
       "      <td>...</td>\n",
       "      <td>363420</td>\n",
       "      <td>365875</td>\n",
       "      <td>364540</td>\n",
       "      <td>365226</td>\n",
       "      <td>364413</td>\n",
       "      <td>367585</td>\n",
       "      <td>369568</td>\n",
       "      <td>371918</td>\n",
       "      <td>371686</td>\n",
       "      <td>358356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>82077.1</td>\n",
       "      <td>81630.7</td>\n",
       "      <td>82352.2</td>\n",
       "      <td>82706.7</td>\n",
       "      <td>...</td>\n",
       "      <td>474844</td>\n",
       "      <td>475592</td>\n",
       "      <td>474627</td>\n",
       "      <td>473162</td>\n",
       "      <td>477369</td>\n",
       "      <td>475492</td>\n",
       "      <td>469662</td>\n",
       "      <td>467351</td>\n",
       "      <td>467963</td>\n",
       "      <td>454027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>72514.7</td>\n",
       "      <td>73155.2</td>\n",
       "      <td>72190.4</td>\n",
       "      <td>71442.9</td>\n",
       "      <td>70630.8</td>\n",
       "      <td>71348.3</td>\n",
       "      <td>71837.5</td>\n",
       "      <td>72237.9</td>\n",
       "      <td>...</td>\n",
       "      <td>390708</td>\n",
       "      <td>388053</td>\n",
       "      <td>393033</td>\n",
       "      <td>386806</td>\n",
       "      <td>392721</td>\n",
       "      <td>393255</td>\n",
       "      <td>400182</td>\n",
       "      <td>390575</td>\n",
       "      <td>391100</td>\n",
       "      <td>386000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0               index        NaN 1995-01-01 00:00:00  \\\n",
       "0               City of London  E09000001               91449   \n",
       "1           Barking & Dagenham  E09000002             50460.2   \n",
       "2                       Barnet  E09000003             93284.5   \n",
       "3                       Bexley  E09000004             64958.1   \n",
       "4                        Brent  E09000005             71306.6   \n",
       "5                      Bromley  E09000006             81671.5   \n",
       "6                       Camden  E09000007              120933   \n",
       "7                      Croydon  E09000008             69158.2   \n",
       "8                       Ealing  E09000009             79885.9   \n",
       "9                      Enfield  E09000010             72514.7   \n",
       "\n",
       "Unnamed: 0 1995-02-01 00:00:00 1995-03-01 00:00:00 1995-04-01 00:00:00  \\\n",
       "0                      82202.8             79120.7             77101.2   \n",
       "1                      51085.8               51269             53133.5   \n",
       "2                      93190.2             92247.5             90762.9   \n",
       "3                      64787.9             64367.5             64277.7   \n",
       "4                      72022.3             72015.8             72965.6   \n",
       "5                      81657.6             81449.3             81124.4   \n",
       "6                       119509              120282              120098   \n",
       "7                      68951.1             68712.4               68610   \n",
       "8                      80897.1             81379.9             82188.9   \n",
       "9                      73155.2             72190.4             71442.9   \n",
       "\n",
       "Unnamed: 0 1995-05-01 00:00:00 1995-06-01 00:00:00 1995-07-01 00:00:00  \\\n",
       "0                      84409.1             94900.5              110128   \n",
       "1                      53042.2             53700.3             52113.1   \n",
       "2                        90258             90107.2             91441.2   \n",
       "3                      63997.1             64252.3             63722.7   \n",
       "4                        73704             74310.5               74127   \n",
       "5                      81542.6             82382.8             82898.5   \n",
       "6                       119929              121887              124028   \n",
       "7                      68844.9             69052.5             69142.5   \n",
       "8                      82077.1             81630.7             82352.2   \n",
       "9                      70630.8             71348.3             71837.5   \n",
       "\n",
       "Unnamed: 0 1995-08-01 00:00:00  ... 2019-06-01 00:00:00 2019-07-01 00:00:00  \\\n",
       "0                       112329  ...              761526              756407   \n",
       "1                      52232.2  ...              293889              297426   \n",
       "2                      92361.3  ...              512694              514668   \n",
       "3                      64432.6  ...              339324              338346   \n",
       "4                        73547  ...              474821              473849   \n",
       "5                      82054.4  ...              430002              434257   \n",
       "6                       125530  ...              871957              890288   \n",
       "7                      68993.4  ...              363420              365875   \n",
       "8                      82706.7  ...              474844              475592   \n",
       "9                      72237.9  ...              390708              388053   \n",
       "\n",
       "Unnamed: 0 2019-08-01 00:00:00 2019-09-01 00:00:00 2019-10-01 00:00:00  \\\n",
       "0                       813770              810455              826227   \n",
       "1                       299421              304778              304579   \n",
       "2                       528577              526670              525678   \n",
       "3                       337523              333340              332920   \n",
       "4                       488784              501533              494770   \n",
       "5                       442189              441058              439178   \n",
       "6                       863171              838170              804713   \n",
       "7                       364540              365226              364413   \n",
       "8                       474627              473162              477369   \n",
       "9                       393033              386806              392721   \n",
       "\n",
       "Unnamed: 0 2019-11-01 00:00:00 2019-12-01 00:00:00 2020-01-01 00:00:00  \\\n",
       "0                       776894              737275              757377   \n",
       "1                       306390              301283              304187   \n",
       "2                       522639              519306              520115   \n",
       "3                       333657              336302              334430   \n",
       "4                       432188              427126              424663   \n",
       "5                       436080              438682              435337   \n",
       "6                       825336              807124              816906   \n",
       "7                       367585              369568              371918   \n",
       "8                       475492              469662              467351   \n",
       "9                       393255              400182              390575   \n",
       "\n",
       "Unnamed: 0 2020-02-01 00:00:00 2020-03-01 00:00:00  \n",
       "0                       765416              792583  \n",
       "1                       304719              327136  \n",
       "2                       520966              532569  \n",
       "3                       334845              331679  \n",
       "4                       471574              446966  \n",
       "5                       436544              430033  \n",
       "6                       818558              881096  \n",
       "7                       371686              358356  \n",
       "8                       467963              454027  \n",
       "9                       391100              386000  \n",
       "\n",
       "[10 rows x 305 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesT = properties.transpose()\n",
    "propertiesT = propertiesT.reindex()\n",
    "propertiesT.columns = propertiesT.iloc[0]\n",
    "propertiesdf = pd.DataFrame(propertiesT)\n",
    "propertiesdf = propertiesdf.drop(propertiesdf.index[0], axis = 0)\n",
    "propertiesdf.reset_index(level = 0, inplace = True)\n",
    "propertiesdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Boroughs</th>\n",
       "      <th>ID</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0            Boroughs         ID 1995-01-01 00:00:00  \\\n",
       "0               City of London  E09000001               91449   \n",
       "1           Barking & Dagenham  E09000002             50460.2   \n",
       "2                       Barnet  E09000003             93284.5   \n",
       "3                       Bexley  E09000004             64958.1   \n",
       "4                        Brent  E09000005             71306.6   \n",
       "\n",
       "Unnamed: 0 1995-02-01 00:00:00 1995-03-01 00:00:00 1995-04-01 00:00:00  \\\n",
       "0                      82202.8             79120.7             77101.2   \n",
       "1                      51085.8               51269             53133.5   \n",
       "2                      93190.2             92247.5             90762.9   \n",
       "3                      64787.9             64367.5             64277.7   \n",
       "4                      72022.3             72015.8             72965.6   \n",
       "\n",
       "Unnamed: 0 1995-05-01 00:00:00 1995-06-01 00:00:00 1995-07-01 00:00:00  \\\n",
       "0                      84409.1             94900.5              110128   \n",
       "1                      53042.2             53700.3             52113.1   \n",
       "2                        90258             90107.2             91441.2   \n",
       "3                      63997.1             64252.3             63722.7   \n",
       "4                        73704             74310.5               74127   \n",
       "\n",
       "Unnamed: 0 1995-08-01 00:00:00  ... 2019-06-01 00:00:00 2019-07-01 00:00:00  \\\n",
       "0                       112329  ...              761526              756407   \n",
       "1                      52232.2  ...              293889              297426   \n",
       "2                      92361.3  ...              512694              514668   \n",
       "3                      64432.6  ...              339324              338346   \n",
       "4                        73547  ...              474821              473849   \n",
       "\n",
       "Unnamed: 0 2019-08-01 00:00:00 2019-09-01 00:00:00 2019-10-01 00:00:00  \\\n",
       "0                       813770              810455              826227   \n",
       "1                       299421              304778              304579   \n",
       "2                       528577              526670              525678   \n",
       "3                       337523              333340              332920   \n",
       "4                       488784              501533              494770   \n",
       "\n",
       "Unnamed: 0 2019-11-01 00:00:00 2019-12-01 00:00:00 2020-01-01 00:00:00  \\\n",
       "0                       776894              737275              757377   \n",
       "1                       306390              301283              304187   \n",
       "2                       522639              519306              520115   \n",
       "3                       333657              336302              334430   \n",
       "4                       432188              427126              424663   \n",
       "\n",
       "Unnamed: 0 2020-02-01 00:00:00 2020-03-01 00:00:00  \n",
       "0                       765416              792583  \n",
       "1                       304719              327136  \n",
       "2                       520966              532569  \n",
       "3                       334845              331679  \n",
       "4                       471574              446966  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesdf = propertiesdf.rename(columns = {propertiesdf.columns[0]:'Boroughs', propertiesdf.columns[1]:'ID'})\n",
    "propertiesdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Boroughs</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Boroughs         ID       Date    Value\n",
       "0      City of London  E09000001 1995-01-01    91449\n",
       "1  Barking & Dagenham  E09000002 1995-01-01  50460.2\n",
       "2              Barnet  E09000003 1995-01-01  93284.5\n",
       "3              Bexley  E09000004 1995-01-01  64958.1\n",
       "4               Brent  E09000005 1995-01-01  71306.6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesdfmelted = pd.melt(propertiesdf, id_vars = ['Boroughs','ID'])\n",
    "propertiesdfmelted = propertiesdfmelted.rename(columns = {propertiesdfmelted.columns[2]:'Date',propertiesdfmelted.columns[3]:'Value'})\n",
    "propertiesdfmelted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boroughs            object\n",
       "ID                  object\n",
       "Date        datetime64[ns]\n",
       "Value              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesdfmelted['Value']=pd.to_numeric(propertiesdfmelted['Value'])\n",
    "propertiesdfmelted.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barking & Dagenham', 'Barnet', 'Bexley', 'Brent', 'Bromley',\n",
       "       'Camden', 'Croydon', 'Ealing', 'Enfield', 'Greenwich', 'Hackney',\n",
       "       'Hammersmith & Fulham', 'Haringey', 'Harrow', 'Havering',\n",
       "       'Hillingdon', 'Hounslow', 'Islington', 'Kensington & Chelsea',\n",
       "       'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton', 'Newham',\n",
       "       'Redbridge', 'Richmond upon Thames', 'Southwark', 'Sutton',\n",
       "       'Tower Hamlets', 'Waltham Forest', 'Wandsworth', 'Westminster'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertiesdfmeltedfiltered = propertiesdfmelted[-propertiesdfmelted['Boroughs'].isna()]\n",
    "#propertiesdfmeltedfiltered[propertiesdfmeltedfiltered['Boroughs'].isna()]\n",
    "uniqueboroughs = propertiesdfmeltedfiltered['Boroughs'].unique()[1:33]\n",
    "propertiesdfmeltedfiltered = propertiesdfmeltedfiltered[propertiesdfmeltedfiltered['Boroughs'].isin(uniqueboroughs)]\n",
    "propertiesdfmeltedfiltered['Boroughs'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "year 0 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         ticksLight = _is_light([label.get_color()\n\u001b[0m\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m'Return a list of Text instances for the major ticklabels.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;34m'Get the tick instances; grow as necessary.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumticks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m             \u001b[0mnumticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0mymax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplaced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'localize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0;31m# look after pytz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: year 0 is out of range"
     ]
    }
   ],
   "source": [
    "bexley = propertiesdfmeltedfiltered[propertiesdfmeltedfiltered['Boroughs'] == 'Bexley']\n",
    "bplot = bexley[['Date','Value']].plot(kind = 'line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Boroughs         ID       Date         Value  Year\n",
      "14515  Kensington & Chelsea  E09000020 2020-03-01  1.396102e+06  2020\n",
      "12835  Kensington & Chelsea  E09000020 2017-04-01  1.399839e+06  2017\n",
      "12739  Kensington & Chelsea  E09000020 2017-02-01  1.412255e+06  2017\n",
      "13603  Kensington & Chelsea  E09000020 2018-08-01  1.418032e+06  2018\n",
      "13267  Kensington & Chelsea  E09000020 2018-01-01  1.463378e+06  2018\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "propertiesdfmeltedfiltered['Year'] = 0\n",
    "for ii in propertiesdfmeltedfiltered['Date']:\n",
    "    propertiesdfmeltedfiltered.iloc[i, propertiesdfmeltedfiltered.columns.get_loc('Year')] = ii.year\n",
    "    i += 1\n",
    "print(propertiesdfmeltedfiltered.sort_values(by = 'Value').tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": [
    "dfg = propertiesdfmeltedfiltered.groupby(by = ['Boroughs', 'Year']).mean().reset_index()\n",
    "boroughs = dfg['Boroughs'].unique()\n",
    "results = {}\n",
    "for ii in boroughs:\n",
    "    tempdf = dfg[dfg['Boroughs'] == ii]\n",
    "    ratio = (tempdf[tempdf['Year'] == 2020].iloc[0,2])/(tempdf[tempdf['Year'] == 2000].iloc[0,2])\n",
    "    results[ii] = ratio\n",
    "results = pd.DataFrame(list(results.items()), columns = ['Borough', 'Ratio'])\n",
    "results = results.sort_values(by = 'Ratio', ascending = False)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course!\n",
    "\n",
    "\n",
    "\n",
    "*Based on the results the buroughs with the biggest price increase are Hackney, Waltham Forest, Newham, Barkin & Dagenham, and Westminster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
